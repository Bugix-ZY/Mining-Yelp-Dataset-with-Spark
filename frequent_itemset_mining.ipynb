{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = \"frequent-itemset-mining\"\n",
    "master = \"local[*]\"\n",
    "\n",
    "conf = SparkConf().setAppName(appName).setMaster(master)\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_file_path  = '/Users/ZhengYang/Documents/yelp_dataset/review.json'\n",
    "business_file_path  = '/Users/ZhengYang/Documents/yelp_dataset/business.json'\n",
    "\n",
    "review_rdd = sc.textFile(review_file_path)\n",
    "business_rdd = sc.textFile(business_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN review.json and business.json by business_id, also filter state == 'NV' \n",
    "# uncomment to generate 'usr_biz.csv'\n",
    "\"\"\"\n",
    "biz_NV = business_rdd \\\n",
    "    .filter(lambda x: json.loads(x)['state'] == 'NV') \\\n",
    "    .map(lambda x: json.loads(x)['business_id']) \\\n",
    "    .collect()\n",
    "    \n",
    "usr2biz_NV = review_rdd \\\n",
    "    .map(lambda x: [json.loads(x)['user_id'], json.loads(x)['business_id']]) \\\n",
    "    .filter(lambda x: x[1] in biz_NV).collect()\n",
    "\n",
    "with open(\"usr_biz.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(usr2biz_NV) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_usr_biz(x):\n",
    "    pair = x.split(',')\n",
    "    return str(pair[0]), [str(pair[1])]\n",
    "\n",
    "\n",
    "def apriori(iterator):\n",
    "    count = {}\n",
    "    result = []\n",
    "    baskets = list(iterator)\n",
    "    \n",
    "    partition_support = (len(baskets) * float(support)) / total_basket\n",
    "\n",
    "    for basket in baskets:\n",
    "        for item in basket[1]:\n",
    "            count[item] = count.get(item, 0) + 1\n",
    "\n",
    "    singletons = set([item for item in count if count[item] >= partition_support])\n",
    "    true_frequent = set([frozenset([item]) for item in singletons])\n",
    "    \n",
    "    size = 2\n",
    "    while len(true_frequent) > 0:\n",
    "        result += true_frequent\n",
    "        candidates = set([a.union(b) for a in true_frequent for b in true_frequent if len(a.union(b)) == size])\n",
    "        count = {}\n",
    "        true_frequent = set()\n",
    "        for basket in baskets:\n",
    "            for candidate in candidates:\n",
    "                if candidate.issubset(basket[1]):\n",
    "                    count[candidate] = count.get(candidate, 0) + 1\n",
    "        size += 1\n",
    "        true_frequent = set([item for item in count if count[item] >= partition_support])\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def full_pass(iterator):\n",
    "    baskets = list(iterator)\n",
    "    count = {}\n",
    "    for candidate in candidates.value:\n",
    "        for basket in baskets:\n",
    "            if candidate.issubset(basket[1]):\n",
    "                count[candidate] = count.get(candidate, 0) + 1\n",
    "    return count.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 50\n",
    "threshold = 70 # only consider the baskets which have more than 70 items\n",
    "\n",
    "rdd_data = sc.textFile('usr_biz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets = rdd_data \\\n",
    "    .map(lambda x: split_to_usr_biz(x)) \\\n",
    "    .reduceByKey(lambda a, b: a + b) \\\n",
    "    .filter(lambda x: len(x[1]) > threshold) \\\n",
    "    .map(lambda x: (x[0], set(x[1])))\n",
    "\n",
    "total_basket = baskets.count()\n",
    "\n",
    "# SON algorithm (2-Phase Map-Reduce)\n",
    "# 1st Map-Reduce Phase: Generate possible candiates in each local chunk\n",
    "first_mapper_output = baskets \\\n",
    "    .mapPartitions(apriori) \\\n",
    "    .map(lambda x: (x, 1))\n",
    "\n",
    "first_reducer_output = first_mapper_output \\\n",
    "    .reduceByKey(lambda a, b: a) \\\n",
    "    .map(lambda x: x[0]) \n",
    "\n",
    "candidates = sc.broadcast(first_reducer_output.collect())\n",
    "\n",
    "# 2nd Map-Reduce Phase: Find ALL Frequent Itemsets (Eliminate False Postives)\n",
    "second_mapper_output = baskets \\\n",
    "    .mapPartitions(full_pass) \n",
    "\n",
    "second_reducer_output = second_mapper_output \\\n",
    "    .reduceByKey(lambda a, b : a + b) \\\n",
    "    .filter(lambda x: x[1] >= support) \\\n",
    "    .collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = [(sorted(item[0]), item[1]) for item in second_reducer_output]\n",
    "frequent_itemsets.sort(key = lambda s: (len(s[0]), s[0]))\n",
    "\n",
    "frequent_singletons = [item for item in frequent_itemsets if len(item[0]) == 1]\n",
    "frequent_pairs = [item for item in frequent_itemsets if len(item[0]) == 2]\n",
    "frequent_triplets = [item for item in frequent_itemsets if len(item[0]) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent singletons: 1312 \n",
      "\n",
      "frequent pairs: 1515 \n",
      "\n",
      "frequent triplets: 13\n",
      "(['4JNXUYY8wbaaDmk3BPzlWw', 'K7lWdNUhCbcnEvI0NhGewg', 'RESDUcs7fIiihp38-d6_6g'], 53)\n",
      "(['4JNXUYY8wbaaDmk3BPzlWw', 'RESDUcs7fIiihp38-d6_6g', 'iCQpiavjjPzJ5_3gPD5Ebg'], 52)\n",
      "(['4k3RlMAMd46DZ_JyZU0lMg', '7sPNbCx7vGAaH7SbNPZ6oA', 'JyxHvtj-syke7m9rbza7mA'], 52)\n",
      "(['4k3RlMAMd46DZ_JyZU0lMg', 'JyxHvtj-syke7m9rbza7mA', 'UPIYuRaZvknINOd1w8kqRQ'], 70)\n",
      "(['4k3RlMAMd46DZ_JyZU0lMg', 'JyxHvtj-syke7m9rbza7mA', 'W8apgXmOxESpoL_EeogC5w'], 50)\n",
      "(['4k3RlMAMd46DZ_JyZU0lMg', 'UPIYuRaZvknINOd1w8kqRQ', 'W8apgXmOxESpoL_EeogC5w'], 51)\n",
      "(['7sPNbCx7vGAaH7SbNPZ6oA', 'JyxHvtj-syke7m9rbza7mA', 'UPIYuRaZvknINOd1w8kqRQ'], 53)\n",
      "(['A5Rkh7UymKm0_Rxm9K2PJw', 'BxKe9Xt_fN6qBzrTofHuEQ', 'FaHADZARwnY4yvlvpnsfGA'], 50)\n",
      "(['A5Rkh7UymKm0_Rxm9K2PJw', 'BxKe9Xt_fN6qBzrTofHuEQ', 'gy-HBIeJGlQHs4RRYDLuHw'], 51)\n",
      "(['A5Rkh7UymKm0_Rxm9K2PJw', 'FaHADZARwnY4yvlvpnsfGA', 'gy-HBIeJGlQHs4RRYDLuHw'], 51)\n",
      "(['IMLrj2klosTFvPRLv56cng', 'igHYkXZMLAc9UdV5VnR_AA', 'qqs7LP4TXAoOrSlaKRfz3A'], 50)\n",
      "(['JyxHvtj-syke7m9rbza7mA', 'UPIYuRaZvknINOd1w8kqRQ', 'j5nPiTwWEFr-VsePew7Sjg'], 58)\n",
      "(['K7lWdNUhCbcnEvI0NhGewg', 'RESDUcs7fIiihp38-d6_6g', 'iCQpiavjjPzJ5_3gPD5Ebg'], 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"frequent singletons: %d \\n\" % len(frequent_singletons))\n",
    "print(\"frequent pairs: %d \\n\" % len(frequent_pairs))\n",
    "print(\"frequent triplets: %d\" % len(frequent_triplets))\n",
    "print(*frequent_triplets, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    TODO: Analyze Frequent Itemsets/\\n    compare\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    TODO: Analyze Frequent Itemsets/\n",
    "    compare\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
